# Documentation MLOps - Projet de Machine Learning en Production

## ğŸ“‹ Table des MatiÃ¨res
1. [Vue d'ensemble du projet](#vue-densemble-du-projet)
2. [Architecture MLOps](#architecture-mlops)
3. [Flux de travail (Workflow)](#flux-de-travail-workflow)
4. [Outils utilisÃ©s](#outils-utilisÃ©s)
5. [Description des modÃ¨les ML](#description-des-modÃ¨les-ml)
6. [FonctionnalitÃ©s avancÃ©es](#fonctionnalitÃ©s-avancÃ©es)
7. [Guide d'utilisation](#guide-dutilisation)

---

## ğŸ¯ Vue d'ensemble du projet

Ce projet dÃ©montre l'implÃ©mentation d'un pipeline MLOps complet pour le dÃ©veloppement, le suivi et le dÃ©ploiement de modÃ¨les de Machine Learning. Le projet explore trois datasets diffÃ©rents avec des problÃ©matiques variÃ©es :

1. **California Housing Dataset** - RÃ©gression : PrÃ©diction des prix immobiliers
2. **Credit Card Fraud Detection** - Classification dÃ©sÃ©quilibrÃ©e : DÃ©tection de fraudes
3. **Customer Churn Prediction** - Classification binaire : PrÃ©diction de dÃ©sabonnement

### Objectifs du projet
- âœ… Versioning du code avec **Git**
- âœ… Suivi des expÃ©riences avec **MLflow**
- âœ… Versioning des donnÃ©es avec **DVC**
- âœ… Automatisation avec **GitHub Actions**
- âœ… Hyperparameter tuning avec **Optuna**
- âœ… DÃ©tection de data drift avec **Evidently**

---

## ğŸ—ï¸ Architecture MLOps

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GitHub Repository                        â”‚
â”‚                    (Code + Configuration)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GitHub Actions (CI/CD)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Linting    â”‚  â”‚   Testing    â”‚  â”‚   Training Pipeline  â”‚  â”‚
â”‚  â”‚   (Flake8)   â”‚  â”‚   (Pytest)   â”‚  â”‚   (Auto-trigger)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DVC (Data Version Control)                              â”‚   â”‚
â”‚  â”‚  - Versioning des datasets                               â”‚   â”‚
â”‚  â”‚  - Pipeline de preprocessing                             â”‚   â”‚
â”‚  â”‚  - MÃ©triques trackÃ©es                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Training & Experimentation                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  MLflow Tracking Server                                  â”‚   â”‚
â”‚  â”‚  - Logging des paramÃ¨tres                                â”‚   â”‚
â”‚  â”‚  - MÃ©triques de performance                              â”‚   â”‚
â”‚  â”‚  - Artifacts (modÃ¨les, plots)                            â”‚   â”‚
â”‚  â”‚  - Model Registry                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Optuna (Hyperparameter Tuning)                         â”‚   â”‚
â”‚  â”‚  - Optimisation bayÃ©sienne                               â”‚   â”‚
â”‚  â”‚  - Pruning automatique                                   â”‚   â”‚
â”‚  â”‚  - Multi-objective optimization                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Monitoring & Validation                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Evidently AI                                            â”‚   â”‚
â”‚  â”‚  - Data Drift Detection                                  â”‚   â”‚
â”‚  â”‚  - Model Performance Monitoring                          â”‚   â”‚
â”‚  â”‚  - Data Quality Reports                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flux de travail (Workflow)

### 1. DÃ©veloppement Local

```bash
# Ã‰tape 1: GÃ©nÃ©rer/TÃ©lÃ©charger les donnÃ©es
python generate_data.py

# Ã‰tape 2: Initialiser DVC pour le versioning
dvc add data/*.csv
git add data/*.csv.dvc .gitignore
git commit -m "Add dataset v1"

# Ã‰tape 3: EntraÃ®ner le modÃ¨le avec MLflow tracking
python train.py

# Ã‰tape 4: ExÃ©cuter le pipeline DVC complet
dvc repro

# Ã‰tape 5: Comparer les expÃ©riences MLflow
mlflow ui  # Ouvre l'interface web
```

### 2. Pipeline d'expÃ©rimentation

```
Data Acquisition â†’ Data Preprocessing â†’ Feature Engineering â†’ 
Model Training â†’ Hyperparameter Tuning â†’ Model Evaluation â†’ 
Model Registration â†’ Monitoring
```

### 3. CI/CD avec GitHub Actions

**DÃ©clencheurs:**
- `git push` sur la branche `main`
- Pull Request
- Changement dans `data/` ou `train.py`

**Ã‰tapes automatisÃ©es:**
1. Linting du code (flake8)
2. Tests unitaires (pytest)
3. EntraÃ®nement automatique du modÃ¨le
4. Validation des mÃ©triques
5. Mise Ã  jour du Model Registry
6. GÃ©nÃ©ration de rapports

---

## ğŸ› ï¸ Outils utilisÃ©s

### 1. **Git** - Versioning du code
- **RÃ´le**: Gestion des versions du code source
- **Usage**: 
  - Branches pour features/expÃ©riences
  - Commits atomiques
  - Tags pour releases
- **Fichiers clÃ©s**: `.gitignore`, `.gitattributes`

### 2. **MLflow** - Suivi des expÃ©riences ML
- **RÃ´le**: Tracking, packaging et dÃ©ploiement de modÃ¨les
- **Composants utilisÃ©s**:
  - **Tracking**: Log des paramÃ¨tres, mÃ©triques, artifacts
  - **Projects**: Packaging reproductible
  - **Models**: Format standardisÃ© pour le dÃ©ploiement
  - **Registry**: Gestion du cycle de vie des modÃ¨les
  
**Exemple d'utilisation:**
```python
with mlflow.start_run(run_name="experiment_1"):
    mlflow.log_param("n_estimators", 100)
    mlflow.log_metric("accuracy", 0.95)
    mlflow.sklearn.log_model(model, "model")
```

### 3. **DVC (Data Version Control)** - Versioning des donnÃ©es
- **RÃ´le**: Gestion des versions de datasets et pipelines
- **FonctionnalitÃ©s**:
  - Versioning de datasets volumineux
  - Pipeline de preprocessing reproductible
  - Tracking des mÃ©triques
  - Remote storage (S3, GCS, Azure, etc.)

**Structure du pipeline:**
```yaml
stages:
  prepare:
    cmd: python prepare_data.py
    deps: [data/raw/]
    outs: [data/processed/]
  
  train:
    cmd: python train.py
    deps: [data/processed/, train.py]
    outs: [models/model.pkl]
    metrics: [metrics/metrics.json]
```

### 4. **GitHub Actions** - CI/CD et Automatisation
- **RÃ´le**: Automatisation des tests, training et dÃ©ploiement
- **Workflows**:
  - Tests automatiques sur chaque commit
  - EntraÃ®nement automatique pÃ©riodique
  - Validation des modÃ¨les
  - DÃ©ploiement en staging/production

### 5. **Optuna** - Optimisation d'hyperparamÃ¨tres (FonctionnalitÃ© avancÃ©e)
- **RÃ´le**: Recherche automatique des meilleurs hyperparamÃ¨tres
- **Algorithmes**: TPE Sampler, Bayesian Optimization
- **Avantages**:
  - Pruning automatique des essais non prometteurs
  - ParallÃ©lisation facile
  - IntÃ©gration native avec MLflow

### 6. **Evidently AI** - Monitoring et Drift Detection (FonctionnalitÃ© avancÃ©e)
- **RÃ´le**: DÃ©tection de dÃ©gradation des modÃ¨les et drift des donnÃ©es
- **Rapports gÃ©nÃ©rÃ©s**:
  - Data Drift Report
  - Data Quality Report
  - Model Performance Report
- **MÃ©triques surveillÃ©es**:
  - Distribution des features
  - CorrÃ©lations
  - Valeurs manquantes
  - Performance du modÃ¨le

---

## ğŸ¤– Description des modÃ¨les ML

### Dataset 1: California Housing (RÃ©gression)

**ProblÃ©matique**: PrÃ©dire le prix mÃ©dian des maisons en Californie

**Features (8)**:
- MedInc: Revenu mÃ©dian du quartier
- HouseAge: Ã‚ge mÃ©dian des maisons
- AveRooms: Nombre moyen de piÃ¨ces
- AveBedrms: Nombre moyen de chambres
- Population: Population du quartier
- AveOccup: Occupation moyenne
- Latitude, Longitude: CoordonnÃ©es gÃ©ographiques

**Target**: Prix mÃ©dian des maisons (en $100k)

**Algorithmes testÃ©s**:
1. Random Forest Regressor (baseline)
2. Gradient Boosting Regressor
3. XGBoost Regressor (optimisÃ© avec Optuna)

**MÃ©triques d'Ã©valuation**:
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- RÂ² Score

### Dataset 2: Credit Card Fraud Detection (Classification dÃ©sÃ©quilibrÃ©e)

**ProblÃ©matique**: DÃ©tecter les transactions frauduleuses

**Features (30)**:
- Time: Temps Ã©coulÃ© depuis la premiÃ¨re transaction
- V1-V28: Features anonymisÃ©es (PCA)
- Amount: Montant de la transaction

**Target**: Class (0 = lÃ©gitime, 1 = fraude)

**DÃ©fis**:
- Dataset hautement dÃ©sÃ©quilibrÃ© (~0.17% de fraudes)
- NÃ©cessite des techniques de rÃ©Ã©quilibrage (SMOTE, undersampling)

**Algorithmes testÃ©s**:
1. Logistic Regression avec class weighting
2. Random Forest avec balanced class weights
3. LightGBM avec scale_pos_weight

**MÃ©triques d'Ã©valuation**:
- Precision, Recall, F1-Score
- AUC-ROC
- Precision-Recall AUC (plus important pour classes dÃ©sÃ©quilibrÃ©es)

### Dataset 3: Customer Churn Prediction (Classification binaire)

**ProblÃ©matique**: PrÃ©dire si un client va rÃ©silier son abonnement

**Features (~20)**:
- DÃ©mographiques: gender, SeniorCitizen, Partner, Dependents
- Services: InternetService, OnlineSecurity, TechSupport, etc.
- Compte: tenure, Contract, PaymentMethod, MonthlyCharges, TotalCharges

**Target**: Churn (Yes/No)

**Algorithmes testÃ©s**:
1. Random Forest Classifier
2. XGBoost Classifier
3. CatBoost (gestion native des features catÃ©gorielles)

**MÃ©triques d'Ã©valuation**:
- Accuracy, Precision, Recall, F1-Score
- AUC-ROC
- Confusion Matrix

---

## ğŸš€ FonctionnalitÃ©s avancÃ©es

### 1. Hyperparameter Tuning avec Optuna

**ImplÃ©mentation**: Recherche automatique des meilleurs hyperparamÃ¨tres

```python
import optuna
from optuna.integration.mlflow import MLflowCallback

def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300),
        'max_depth': trial.suggest_int('max_depth', 3, 15),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3)
    }
    
    model = XGBClassifier(**params)
    model.fit(X_train, y_train)
    
    return model.score(X_val, y_val)

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)
```

**Avantages**:
- Optimisation bayÃ©sienne intelligente
- Pruning des essais non prometteurs
- Tracking automatique dans MLflow
- Visualisation des importances des hyperparamÃ¨tres

### 2. Data Drift Detection avec Evidently

**ImplÃ©mentation**: Surveillance continue de la qualitÃ© des donnÃ©es

```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, DataQualityPreset

report = Report(metrics=[
    DataDriftPreset(),
    DataQualityPreset()
])

report.run(reference_data=train_data, current_data=new_data)
report.save_html("reports/data_drift_report.html")
```

**DÃ©tections**:
- Drift dans la distribution des features
- Changements dans les corrÃ©lations
- Augmentation des valeurs manquantes
- DÃ©gradation de performance du modÃ¨le

**Alertes**:
- Notification si drift dÃ©tectÃ©
- Recommandation de rÃ©entraÃ®nement
- GÃ©nÃ©ration de rapports HTML interactifs

---

## ğŸ“– Guide d'utilisation

### Installation

```bash
# Cloner le repository
git clone https://github.com/WissemHarhouri/MLOPS.git
cd mlops-mlflow-tp

# CrÃ©er un environnement virtuel
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Installer les dÃ©pendances
pip install -r requirements.txt

# Initialiser DVC
dvc init
```

### Workflow complet

```bash
# 1. GÃ©nÃ©rer les donnÃ©es (Dataset 1)
python generate_data.py --dataset california_housing

# 2. Ajouter au versioning DVC
dvc add data/housing_data.csv
git add data/housing_data.csv.dvc
git commit -m "Add California Housing dataset"

# 3. EntraÃ®ner le modÃ¨le avec tracking MLflow
python train.py --dataset california_housing --tune-hyperparameters

# 4. Visualiser les rÃ©sultats MLflow
mlflow ui
# Ouvrir http://localhost:5000

# 5. ExÃ©cuter le pipeline DVC
dvc repro

# 6. Changer de dataset
python generate_data.py --dataset credit_fraud
dvc add data/credit_data.csv
git add data/credit_data.csv.dvc
git commit -m "Switch to Credit Fraud dataset"

# 7. RÃ©entraÃ®ner
python train.py --dataset credit_fraud

# 8. DÃ©tecter le data drift
python detect_drift.py --reference-data data/housing_data.csv --current-data data/credit_data.csv

# 9. Comparer les rÃ©sultats
python compare_results.py
```

### Commandes utiles

```bash
# MLflow
mlflow ui                          # Interface web
mlflow models serve -m models:/BestModel/Production  # Servir un modÃ¨le

# DVC
dvc status                         # Ã‰tat du pipeline
dvc dag                            # Visualiser le DAG
dvc metrics show                   # Afficher les mÃ©triques
dvc plots show                     # GÃ©nÃ©rer des graphiques

# Git
git log --oneline                  # Historique
git tag v1.0.0                     # CrÃ©er un tag
```

---

## ğŸ“Š Structure du projet

```
mlops-mlflow-tp/
â”œâ”€â”€ data/                          # DonnÃ©es (versionnÃ© avec DVC)
â”‚   â”œâ”€â”€ housing_data.csv
â”‚   â”œâ”€â”€ credit_data.csv
â”‚   â””â”€â”€ churn_data.csv
â”œâ”€â”€ models/                        # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ model.pkl
â”œâ”€â”€ mlruns/                        # MLflow tracking
â”œâ”€â”€ notebooks/                     # Notebooks d'exploration
â”œâ”€â”€ reports/                       # Rapports Evidently
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ mlops-pipeline.yml    # GitHub Actions
â”œâ”€â”€ generate_data.py              # GÃ©nÃ©ration de datasets
â”œâ”€â”€ train.py                      # EntraÃ®nement avec MLflow
â”œâ”€â”€ tune_hyperparameters.py       # Optimisation Optuna
â”œâ”€â”€ detect_drift.py               # DÃ©tection drift Evidently
â”œâ”€â”€ compare_results.py            # Comparaison des modÃ¨les
â”œâ”€â”€ dvc.yaml                      # Pipeline DVC
â”œâ”€â”€ dvc.lock                      # Lock file DVC
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â”œâ”€â”€ DOCUMENTATION.md              # Ce fichier
â””â”€â”€ RESULTS.md                    # RÃ©sultats et analyses
```

---

## ğŸ“ Concepts MLOps illustrÃ©s

1. **ReproductibilitÃ©**: DVC + MLflow garantissent la reproduction exacte des expÃ©riences
2. **Versioning**: Code (Git), DonnÃ©es (DVC), ModÃ¨les (MLflow)
3. **Automatisation**: GitHub Actions pour CI/CD
4. **Monitoring**: Evidently pour dÃ©tecter les drifts
5. **Optimisation**: Optuna pour le tuning automatique
6. **Collaboration**: Tracking centralisÃ© des expÃ©riences

---

## ğŸ“š Ressources

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [DVC Documentation](https://dvc.org/doc)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [Evidently Documentation](https://docs.evidentlyai.com/)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)

---

**Date de crÃ©ation**: Janvier 2026  
**Auteur**: Wissem Harhouri  
**Version**: 1.0.0
