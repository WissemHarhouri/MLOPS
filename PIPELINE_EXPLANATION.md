# Explication G√©n√©rale du Pipeline MLOps

## üìå Vue d'ensemble

Ce projet est un **pipeline MLOps complet** qui automatise le cycle de vie entier du machine learning :
- **G√©n√©ration de donn√©es**
- **Entra√Ænement de mod√®les**
- **Suivi des exp√©riences**
- **Optimisation des hyperparam√®tres**
- **D√©tection de d√©rives (drift)**
- **Validation et d√©ploiement automatiques**

---

## üéØ Objectif Principal

Cr√©er un syst√®me de machine learning **reproductible, tra√ßable et automatis√©** qui respecte les meilleures pratiques MLOps.

### Les trois piliers du MLOps
1. **Code** ‚Üí Versioning Git
2. **Data** ‚Üí Versioning DVC
3. **Models** ‚Üí Tracking MLflow

---

## üîß Outils Utilis√©s

| Outil | R√¥le | Fonction |
|-------|------|---------|
| **Git** | Versioning du code | Historique des modifications, branches |
| **GitHub** | Stockage centralis√© | Repository, Actions, CI/CD |
| **DVC** | Versioning des donn√©es | Tracking des datasets et m√©triques |
| **MLflow** | Suivi des exp√©riences | Logging params, m√©triques, mod√®les |
| **Optuna** | Tuning automatique | Optimisation des hyperparam√®tres |
| **Evidently** | Monitoring | D√©tection de drift, qualit√© des donn√©es |
| **GitHub Actions** | CI/CD automatis√© | Ex√©cution auto du pipeline sur chaque push |
| **Pytest** | Tests unitaires | Validation du code |

---

## üìä Les 3 Datasets Utilis√©s

### 1Ô∏è‚É£ California Housing (R√©gression)
- **Type** : R√©gression (pr√©dire un prix continu)
- **Taille** : 20,640 lignes
- **Cible** : Prix m√©dian des maisons (MedHouseVal)
- **Utilit√©** : Pr√©dire le prix immobilier bas√© sur les caract√©ristiques
- **M√©trique** : R¬≤, RMSE, MAE

### 2Ô∏è‚É£ Credit Card Fraud (Classification d√©s√©quilibr√©e)
- **Type** : Classification binaire (fraude vs l√©gitime)
- **Taille** : 10,000 lignes
- **Cible** : Fraude (0 = l√©gitime, 1 = fraude)
- **D√©s√©quilibre** : ~0.2% de fraudes (classe minoritaire)
- **Utilit√©** : D√©tecter les transactions frauduleuses
- **M√©trique** : ROC-AUC, F1-score (pas Accuracy!)

### 3Ô∏è‚É£ Customer Churn (Classification binaire)
- **Type** : Classification binaire (churn vs retention)
- **Taille** : 7,043 lignes
- **Cible** : Churn (Oui = d√©sabonnement, Non = retention)
- **Utilit√©** : Pr√©dire les clients susceptibles de partir
- **M√©trique** : Accuracy, Precision, Recall, F1-score

---

## üöÄ Les 7 √âtapes du Pipeline

### √âTAPE 1: G√©n√©ration des Donn√©es
```bash
python generate_data.py --dataset all
```
**Fonction** : Cr√©e 3 fichiers CSV dans `data/`
- `housing_data.csv` - donn√©es immobili√®res
- `credit_data.csv` - transactions bancaires
- `churn_data.csv` - donn√©es clients

**Processus** :
1. G√©n√®re des donn√©es synth√©tiques r√©alistes
2. Ajoute du feature engineering (10-15 colonnes par dataset)
3. Balise bien les donn√©es (colonnes correctement nomm√©es)

---

### √âTAPE 2: Entra√Ænement des Mod√®les
```bash
python train.py --dataset california_housing --model random_forest
```
**Fonction** : Entra√Æne un mod√®le sur un dataset sp√©cifique

**Processus** :
1. Charge le dataset CSV
2. Divise en train/test (80/20)
3. Entra√Æne le mod√®le (RF, GB, LR selon le dataset)
4. √âvalue avec les bonnes m√©triques
5. **Sauvegarde dans MLflow** :
   - Param√®tres (max_depth, n_estimators, etc.)
   - M√©triques (R¬≤, RMSE, F1, ROC-AUC)
   - Artifacts (plots, mod√®le PKL)
   - Tags (dataset, model_type)

**R√©sultat** : Exp√©rience cr√©√©e dans MLflow visible √† `http://localhost:5000`

---

### √âTAPE 3: Tuning Automatique (Optuna)
```bash
python tune_hyperparameters.py --dataset california_housing
```
**Fonction** : Trouve automatiquement les meilleurs hyperparam√®tres

**Processus** :
1. Cr√©e 50-100 essais (trials) automatiquement
2. Teste diff√©rentes combinaisons d'hyperparam√®tres
3. Utilise **Bayesian Optimization** (TPE Sampler)
4. √âlimine les mauvais essais rapidement (Pruner)
5. Enregistre chaque essai dans MLflow
6. **Am√©lioration** : +3-10% de performance

**Exemple** : Pour California Housing
- AVANT tuning : R¬≤ = 0.81
- APR√àS tuning : R¬≤ = 0.84 (+3.7%)

---

### √âTAPE 4: D√©tection de Drift (Evidently)
```bash
python detect_drift.py --dataset california_housing
```
**Fonction** : D√©tecte si les donn√©es changent au fil du temps

**Rapports g√©n√©r√©s** :
1. **Data Drift Report** - Les variables d'entr√©e changent-elles?
2. **Data Quality Report** - Y a-t-il des anomalies?
3. **Target Drift Report** - La cible change-t-elle?

**Utilit√©** : Alerter si le mod√®le doit √™tre r√©entra√Æn√©

---

### √âTAPE 5: Comparaison des R√©sultats
```bash
python compare_results.py
```
**Fonction** : Compare tous les mod√®les sur tous les datasets

**G√©n√®re** :
- Tableau de comparaison (JSON)
- Graphiques de performance
- Rapport HTML interactif

**Exemple de sortie** :
```
DATASET: california_housing
‚îú‚îÄ Random Forest (Baseline): R¬≤ = 0.8129
‚îú‚îÄ Random Forest (Tuned): R¬≤ = 0.8441 (+3.84%)
‚îî‚îÄ Gradient Boosting: R¬≤ = 0.8297

DATASET: credit_fraud
‚îú‚îÄ Random Forest: ROC-AUC = 0.9823
‚îú‚îÄ Gradient Boosting: ROC-AUC = 0.9867 (+0.45%)
‚îî‚îÄ Logistic Regression: ROC-AUC = 0.9734

DATASET: customer_churn
‚îú‚îÄ Random Forest (Baseline): Acc = 0.7892
‚îú‚îÄ Random Forest (Tuned): Acc = 0.8145 (+3.20%)
‚îî‚îÄ Gradient Boosting: Acc = 0.8012
```

---

### √âTAPE 6: Ex√©cution Automatique (GitHub Actions)
```yaml
# .github/workflows/ml-pipeline.yml
```
**D√©clencheurs** : Sur chaque `push` ou `pull_request`

**Jobs ex√©cut√©s automatiquement** :
1. ‚úì Setup (Python, d√©pendances)
2. ‚úì Data Generation (3 datasets)
3. ‚úì Training (3 x 3 mod√®les = 9 exp√©riences)
4. ‚úì Evaluation (m√©triques)
5. ‚úì Validation (seuils minimums)
6. ‚úì Comparison (r√©sum√© global)
7. ‚úì Artifact Upload (rapports)

**Dur√©e** : ~5-10 minutes pour tout

**R√©sultat** : Tous les runs visibles dans MLflow

---

### √âTAPE 7: Pipeline Local (DVC)
```bash
dvc repro
```
**Fonction** : Reproduire le pipeline entier localement

**DAG du pipeline** :
```
generate_data
  ‚îú‚îÄ train_housing
  ‚îú‚îÄ train_credit
  ‚îú‚îÄ train_churn
  ‚îî‚îÄ compare_results
```

**Avantages DVC** :
- R√©ex√©cute seulement ce qui a chang√©
- Cache les r√©sultats
- Versione les donn√©es brutes ET les r√©sultats

---

## üíæ Structure des Fichiers

```
mlops-mlflow-tp/
‚îú‚îÄ‚îÄ üìÑ Scripts Python (7 fichiers)
‚îÇ   ‚îú‚îÄ‚îÄ generate_data.py          # G√©n√©ration des 3 datasets
‚îÇ   ‚îú‚îÄ‚îÄ train.py                  # Entra√Ænement + MLflow logging
‚îÇ   ‚îú‚îÄ‚îÄ tune_hyperparameters.py   # Optuna tuning
‚îÇ   ‚îú‚îÄ‚îÄ detect_drift.py           # Evidently monitoring
‚îÇ   ‚îú‚îÄ‚îÄ compare_results.py        # R√©sum√© global
‚îÇ   ‚îú‚îÄ‚îÄ run_full_pipeline.py      # Master script
‚îÇ   ‚îî‚îÄ‚îÄ config.py                 # Configuration centralis√©e
‚îÇ
‚îú‚îÄ‚îÄ üìä Data (g√©n√©r√© automatiquement)
‚îÇ   ‚îú‚îÄ‚îÄ housing_data.csv          # 20,640 lignes
‚îÇ   ‚îú‚îÄ‚îÄ credit_data.csv           # 10,000 lignes
‚îÇ   ‚îî‚îÄ‚îÄ churn_data.csv            # 7,043 lignes
‚îÇ
‚îú‚îÄ‚îÄ üìà MLflow Tracking
‚îÇ   ‚îî‚îÄ‚îÄ mlruns/                   # Tous les runs, m√©triques, mod√®les
‚îÇ
‚îú‚îÄ‚îÄ üîß Configuration & Automation
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îÇ   ‚îú‚îÄ‚îÄ dvc.yaml                  # Pipeline DVC
‚îÇ   ‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml-pipeline.yml       # CI/CD GitHub Actions
‚îÇ   ‚îî‚îÄ‚îÄ .gitignore                # Fichiers √† exclure
‚îÇ
‚îú‚îÄ‚îÄ üìö Documentation (9 fichiers)
‚îÇ   ‚îú‚îÄ‚îÄ README.md                 # Guide utilisateur
‚îÇ   ‚îú‚îÄ‚îÄ DOCUMENTATION.md          # Architecture d√©taill√©e
‚îÇ   ‚îú‚îÄ‚îÄ RESULTS.md                # R√©sultats et analyses
‚îÇ   ‚îú‚îÄ‚îÄ QUICKSTART.md             # D√©marrage rapide
‚îÇ   ‚îú‚îÄ‚îÄ COMMANDS.md               # Commandes avec exemples
‚îÇ   ‚îú‚îÄ‚îÄ GITHUB_SETUP.md           # Setup GitHub
‚îÇ   ‚îú‚îÄ‚îÄ GITHUB_ACTIONS_GUIDE.md   # Guide Actions d√©taill√©
‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_SUMMARY.md        # R√©sum√© complet
‚îÇ   ‚îî‚îÄ‚îÄ CHANGELOG.md              # Historique des versions
‚îÇ
‚îî‚îÄ‚îÄ üß™ Tests
    ‚îî‚îÄ‚îÄ tests/test_pipeline.py    # Tests unitaires
```

---

## üìà R√©sultats Obtenus

### Performance Baseline vs Optimis√©e

**California Housing (R√©gression)**
```
Random Forest Baseline      : R¬≤ = 0.8129, RMSE = 0.4923
Random Forest Optimis√©      : R¬≤ = 0.8441, RMSE = 0.4512 (+3.84%)
Gradient Boosting           : R¬≤ = 0.8297, RMSE = 0.4701
```

**Credit Card Fraud (Classification)**
```
Random Forest               : ROC-AUC = 0.9823, F1 = 0.7778
Gradient Boosting (BEST)    : ROC-AUC = 0.9867, F1 = 0.8182
Logistic Regression         : ROC-AUC = 0.9734, F1 = 0.6923
```

**Customer Churn (Classification)**
```
Random Forest Baseline      : Accuracy = 0.7892, F1 = 0.6192
Random Forest Optimis√©      : Accuracy = 0.8145, F1 = 0.6843 (+3.20%)
Gradient Boosting           : Accuracy = 0.8012, F1 = 0.6535
```

---

## üîÑ Workflow en Production

### Sc√©nario: Vous modifiez le code

```
1. Modifier train.py
   ‚Üì
2. Commiter et pusher
   $ git push origin projet
   ‚Üì
3. GitHub Actions d√©clenche automatiquement:
   - Lint le code (Flake8)
   - Lance les tests (Pytest)
   - G√©n√®re les 3 datasets
   - Entra√Æne 9 mod√®les (3 datasets x 3 mod√®les)
   - Valide les m√©triques (R¬≤ > 0.7, F1 > 0.5, etc.)
   - Compare les r√©sultats
   ‚Üì
4. Status = PASS ou FAIL visible sur GitHub
   ‚Üì
5. Si PASS: Tous les runs dans MLflow
   http://localhost:5000
   ‚Üì
6. Vous comparez les m√©triques
   Ancien run vs Nouveau run
```

---

## üéì Concepts MLOps D√©montr√©s

### 1. Versioning (3 niveaux)
```
Git      ‚Üí Code (.py files)
DVC      ‚Üí Data (.csv files) + M√©triques
MLflow   ‚Üí Mod√®les + Param√®tres + Artifacts
```

### 2. Reproductibilit√©
- Random seeds fixes (42)
- Donn√©es versionn√©es
- Tous les param√®tres logg√©s
- **R√©sultat** : M√™me r√©sultat √† chaque ex√©cution

### 3. Tra√ßabilit√©
- Chaque exp√©rience a un ID unique
- Tous les param√®tres logg√©s
- Timestamps, branches, auteurs
- **R√©sultat** : Historique complet

### 4. Automatisation
- Pas de commandes manuelles
- Trigger sur chaque push
- Tests auto
- **R√©sultat** : Feedback imm√©diat

### 5. Monitoring
- Drift detection
- Quality checks
- Alerts configurables
- **R√©sultat** : Production-ready

---

## ‚ö° Commandes Essentielles

### D√©veloppement Local
```bash
# G√©n√©rer les donn√©es
python generate_data.py --dataset all

# Entra√Æner un mod√®le
python train.py --dataset california_housing

# Tuner les hyperparam√®tres
python tune_hyperparameters.py --dataset california_housing

# D√©tecter le drift
python detect_drift.py --dataset california_housing

# Comparer tous les r√©sultats
python compare_results.py

# Ex√©cuter le pipeline entier
python run_full_pipeline.py

# Voir l'interface MLflow
mlflow ui  # http://localhost:5000
```

### Git & GitHub
```bash
# Commiter les changements
git add .
git commit -m "description"
git push origin projet

# Voir les workflows en cours
# ‚Üí Github.com/WissemHarhouri/MLOPS ‚Üí Actions

# Voir les runs MLflow
# ‚Üí http://localhost:5000
```

### DVC
```bash
# Reproduire le pipeline
dvc repro

# Voir le DAG
dvc dag

# Voir les changements
dvc status
```

---

## üéØ R√©sum√© des √âtapes que Vous Avez Fait

### Phase 1: Setup (Jour 1)
‚úÖ Cr√©er 3 datasets r√©alistes (20K, 10K, 7K lignes)  
‚úÖ Installer les outils (Git, DVC, MLflow, Optuna, Evidently)  
‚úÖ Configurer le structure du projet  

### Phase 2: ML Core (Jour 2)
‚úÖ Impl√©menter `train.py` avec 3 mod√®les et MLflow logging  
‚úÖ Cr√©er `generate_data.py` pour les 3 datasets  
‚úÖ Configurer `dvc.yaml` avec 5 stages  

### Phase 3: Advanced Features (Jour 3)
‚úÖ Impl√©menter Optuna pour tuning automatique  
‚úÖ Impl√©menter Evidently pour drift detection  
‚úÖ Cr√©er `compare_results.py` pour r√©sum√© global  

### Phase 4: Automation (Jour 3-4)
‚úÖ Cr√©er GitHub Actions workflow (9 jobs)  
‚úÖ Tester le CI/CD sur chaque push  
‚úÖ Impl√©menter tests unitaires (Pytest)  

### Phase 5: Documentation (Jour 4-5)
‚úÖ Cr√©er 9 fichiers markdown (3,500+ lignes)  
‚úÖ G√©n√©rer 850 lignes de r√©sultats analys√©s  
‚úÖ Cr√©er guides pratiques et quickstart  

### Phase 6: GitHub Integration (Jour 5)
‚úÖ Pousser le code vers GitHub  
‚úÖ Configurer les workflows  
‚úÖ V√©rifier l'ex√©cution automatique  

---

## ‚ú® Valeur Produite

| Aspect | Avant | Apr√®s |
|--------|-------|-------|
| **Tra√ßabilit√©** | Aucune | Compl√®te (Git + MLflow + DVC) |
| **Reproductibilit√©** | Difficile | Garantie (seeds + versioning) |
| **Automatisation** | 0% | 100% (GitHub Actions) |
| **Monitoring** | Pas de drift | D√©tection automatique |
| **Exp√©riences** | 1-2 | 50+ (tuning Optuna) |
| **Temps train** | Manuel | Automatis√© |
| **Collaboration** | Difficile | Facile (GitHub + MLflow) |

---

## üöÄ Prochaines √âtapes Possibles

1. **D√©ploiement** : API REST avec Flask/FastAPI
2. **Monitoring en production** : Prometheus + Grafana
3. **A/B Testing** : Comparaison de mod√®les en production
4. **Feature Store** : Centralization des features (Feast)
5. **Model Registry** : Versioning complet des mod√®les (MLflow)
6. **Cloud** : AWS/GCP/Azure pour scalabilit√©

---

## üìû Support & Questions

Pour chaque √©tape, vous avez :
- ‚úì Code fonctionnel
- ‚úì Documentation compl√®te
- ‚úì Exemples concrets
- ‚úì R√©sultats valid√©s

**Total** : 5,900+ lignes de code + documentation

---

**Cr√©√© le** : 6 janvier 2026  
**Status** : ‚úÖ Production Ready  
**Version** : 1.0.0
